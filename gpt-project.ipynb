{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f57bc7a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-17T22:09:44.865451Z",
     "iopub.status.busy": "2025-11-17T22:09:44.864804Z",
     "iopub.status.idle": "2025-11-17T22:09:49.131983Z",
     "shell.execute_reply": "2025-11-17T22:09:49.131177Z"
    },
    "papermill": {
     "duration": 4.273477,
     "end_time": "2025-11-17T22:09:49.133455",
     "exception": false,
     "start_time": "2025-11-17T22:09:44.859978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576af5c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:09:49.140627Z",
     "iopub.status.busy": "2025-11-17T22:09:49.140297Z",
     "iopub.status.idle": "2025-11-17T22:09:49.162258Z",
     "shell.execute_reply": "2025-11-17T22:09:49.161748Z"
    },
    "papermill": {
     "duration": 0.026616,
     "end_time": "2025-11-17T22:09:49.163230",
     "exception": false,
     "start_time": "2025-11-17T22:09:49.136614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers of transformer blocks\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        # d_out: output dimension\n",
    "        # head_dim: is the dimension of context vector before we concatenate them\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"  \n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        keys = self.W_key(x) # shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        \n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        \n",
    "        return context_vec\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = nn.LayerNorm(cfg['emb_dim'], bias=cfg['qkv_bias'])\n",
    "        self.layer_norm2 = nn.LayerNorm(cfg['emb_dim'], bias=cfg['qkv_bias'])\n",
    "        self.attn = MultiHeadAttention(\n",
    "            d_in=cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            qkv_bias=cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.dropout = nn.Dropout(cfg['drop_rate'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.dropout(self.ff(x))\n",
    "        x += shortcut\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg['n_layers'])])\n",
    "        self.final_norm = nn.LayerNorm(cfg['emb_dim'], bias=cfg['qkv_bias'])\n",
    "        self.out_head = nn.Linear(cfg['emb_dim'], cfg['vocab_size'], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embed = self.token_emb(in_idx)\n",
    "        pos_embed = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embed + pos_embed\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        x = self.out_head(x)\n",
    "        return x\n",
    "\n",
    "    # check devices here\n",
    "    def generate(self, idx, max_new_tokens, context_size, device, temperature=0.0, top_k=None, eos_id=None):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx = idx.to(device)\n",
    "            idx_cond = idx[:, -context_size:]\n",
    "            with torch.no_grad():\n",
    "                logits = self(idx_cond)\n",
    "            \n",
    "            logits = logits[:, -1, :] # output embed of the last token dim: (batch, vocab_size)\n",
    "            if top_k is not None:\n",
    "                top_logits, top_pos = torch.topk(logits, top_k)\n",
    "                min_val = top_logits[:, -1]\n",
    "                # we use instead the following code\n",
    "                tmp_logits = torch.empty_like(logits)\n",
    "                tmp_logits.copy_(logits)\n",
    "                logits = torch.full_like(logits, -torch.inf) # tensor contains infinity values only\n",
    "                logits[:, top_pos] = tmp_logits[:, top_pos]\n",
    "            \n",
    "            if temperature > 0.0:\n",
    "                logits = logits / temperature\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            else:\n",
    "                idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "    \n",
    "            if idx_next == eos_id:\n",
    "                break\n",
    "                \n",
    "            idx = torch.cat((idx, idx_next), dim=-1)\n",
    "        return idx\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        \n",
    "        for idx in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[idx : idx+max_length]\n",
    "            target_chunk = token_ids[idx+1 : idx+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, \n",
    "                         shuffle=True, drop_last=True, num_workers=0):\n",
    "    \n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    # print(len(dataset))\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "                           num_workers=num_workers, drop_last=drop_last)\n",
    "    return dataloader\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5aa1e",
   "metadata": {
    "papermill": {
     "duration": 0.002538,
     "end_time": "2025-11-17T22:09:49.168496",
     "exception": false,
     "start_time": "2025-11-17T22:09:49.165958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df0a1a57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:09:49.174500Z",
     "iopub.status.busy": "2025-11-17T22:09:49.174295Z",
     "iopub.status.idle": "2025-11-17T22:09:52.212517Z",
     "shell.execute_reply": "2025-11-17T22:09:52.211793Z"
    },
    "papermill": {
     "duration": 3.042815,
     "end_time": "2025-11-17T22:09:52.213874",
     "exception": false,
     "start_time": "2025-11-17T22:09:49.171059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1135875,\n",
       " 'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "with open('/kaggle/input/shakespeare-plus-verdict/verdict_plus_shakespeare.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "len(txt), txt[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d757a4a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:09:52.220956Z",
     "iopub.status.busy": "2025-11-17T22:09:52.220731Z",
     "iopub.status.idle": "2025-11-17T22:09:52.947627Z",
     "shell.execute_reply": "2025-11-17T22:09:52.947036Z"
    },
    "papermill": {
     "duration": 0.731954,
     "end_time": "2025-11-17T22:09:52.948993",
     "exception": false,
     "start_time": "2025-11-17T22:09:52.217039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device is: {device}')\n",
    "train_ratio = 0.85\n",
    "split_indx = int(train_ratio * len(txt))\n",
    "train_data = txt[:split_indx]\n",
    "val_data = txt[split_indx:]\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=16,\n",
    "    max_length=16,\n",
    "    stride=12,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=16,\n",
    "    max_length=16,\n",
    "    stride=12,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa099e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:09:52.955967Z",
     "iopub.status.busy": "2025-11-17T22:09:52.955727Z",
     "iopub.status.idle": "2025-11-17T22:09:52.960153Z",
     "shell.execute_reply": "2025-11-17T22:09:52.959614Z"
    },
    "papermill": {
     "duration": 0.009219,
     "end_time": "2025-11-17T22:09:52.961270",
     "exception": false,
     "start_time": "2025-11-17T22:09:52.952051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1504, 283)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "929e765e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:09:52.968119Z",
     "iopub.status.busy": "2025-11-17T22:09:52.967915Z",
     "iopub.status.idle": "2025-11-17T22:09:52.973089Z",
     "shell.execute_reply": "2025-11-17T22:09:52.972523Z"
    },
    "papermill": {
     "duration": 0.009868,
     "end_time": "2025-11-17T22:09:52.974147",
     "exception": false,
     "start_time": "2025-11-17T22:09:52.964279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(dataloader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(dataloader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(dataloader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(dataloader))\n",
    "\n",
    "    for i, (input_batch, output_batch) in enumerate(dataloader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, output_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bfe11a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:09:52.980960Z",
     "iopub.status.busy": "2025-11-17T22:09:52.980765Z",
     "iopub.status.idle": "2025-11-17T22:09:52.989418Z",
     "shell.execute_reply": "2025-11-17T22:09:52.988919Z"
    },
    "papermill": {
     "duration": 0.013457,
     "end_time": "2025-11-17T22:09:52.990500",
     "exception": false,
     "start_time": "2025-11-17T22:09:52.977043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                      eval_freq, eval_iter, start_context, tokenizer, early_stopping):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader,\n",
    "                                                      device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f'Epoch {epoch+1} (Step {global_step:06d}): '\n",
    "                     f'Train loss {train_loss:.3f}, Val loss {val_loss:.3f}')\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "        early_stopping(val_loss, model)\n",
    "        # Check early stopping condition\n",
    "        if early_stopping.early_stop:\n",
    "            early_stopping.load_best_model(model)\n",
    "            print('Early stopping condition executed')\n",
    "            break\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "            \n",
    "        logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdims=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=-1)\n",
    "    \n",
    "    return idx\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, encoded, 50, context_size)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace('\\n', ' '))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26e9ee35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:09:52.997213Z",
     "iopub.status.busy": "2025-11-17T22:09:52.997000Z",
     "iopub.status.idle": "2025-11-17T22:09:53.000679Z",
     "shell.execute_reply": "2025-11-17T22:09:53.000141Z"
    },
    "papermill": {
     "duration": 0.008197,
     "end_time": "2025-11-17T22:09:53.001652",
     "exception": false,
     "start_time": "2025-11-17T22:09:52.993455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension because model works with batches not 1D vector\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7fa747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:09:53.008360Z",
     "iopub.status.busy": "2025-11-17T22:09:53.008164Z",
     "iopub.status.idle": "2025-11-17T22:10:20.618925Z",
     "shell.execute_reply": "2025-11-17T22:10:20.618237Z"
    },
    "papermill": {
     "duration": 27.615607,
     "end_time": "2025-11-17T22:10:20.620058",
     "exception": false,
     "start_time": "2025-11-17T22:09:53.004451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Losses:\n",
      "Train Loss: 10.96916237536897\n",
      "Validation Loss: 10.96435064983031\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f'Initial Losses:\\nTrain Loss: {train_loss}\\nValidation Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f60b33d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:10:20.627106Z",
     "iopub.status.busy": "2025-11-17T22:10:20.626891Z",
     "iopub.status.idle": "2025-11-17T22:10:20.631473Z",
     "shell.execute_reply": "2025-11-17T22:10:20.630796Z"
    },
    "papermill": {
     "duration": 0.009414,
     "end_time": "2025-11-17T22:10:20.632611",
     "exception": false,
     "start_time": "2025-11-17T22:10:20.623197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1504, 283)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59bef720",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-17T22:10:20.639600Z",
     "iopub.status.busy": "2025-11-17T22:10:20.638949Z",
     "iopub.status.idle": "2025-11-17T22:32:38.201605Z",
     "shell.execute_reply": "2025-11-17T22:32:38.200617Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 1337.567435,
     "end_time": "2025-11-17T22:32:38.202908",
     "exception": false,
     "start_time": "2025-11-17T22:10:20.635473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000): Train loss 9.515, Val loss 9.334\n",
      "Epoch 1 (Step 000250): Train loss 5.551, Val loss 5.308\n",
      "Epoch 1 (Step 000500): Train loss 5.199, Val loss 4.801\n",
      "Epoch 1 (Step 000750): Train loss 4.852, Val loss 4.619\n",
      "Epoch 1 (Step 001000): Train loss 4.797, Val loss 4.566\n",
      "Epoch 1 (Step 001250): Train loss 4.667, Val loss 4.445\n",
      "Epoch 1 (Step 001500): Train loss 4.561, Val loss 4.382\n",
      "Every effort moves you, And so, and so, and so, and so, and so, and so, and so, and so, and so, and so, and so, and so, and so, and so, and so, and so,\n",
      "Epoch 2 (Step 001750): Train loss 4.455, Val loss 4.404\n",
      "Epoch 2 (Step 002000): Train loss 4.365, Val loss 4.321\n",
      "Epoch 2 (Step 002250): Train loss 4.343, Val loss 4.314\n",
      "Epoch 2 (Step 002500): Train loss 4.233, Val loss 4.322\n",
      "Epoch 2 (Step 002750): Train loss 4.155, Val loss 4.270\n",
      "Epoch 2 (Step 003000): Train loss 4.241, Val loss 4.229\n",
      "Every effort moves you, And therefore I'll not to the king.  DUCHESS OF YORK: DUKE VINCENTIO: DUKE VINCENTIO: DUKE VINCENTIO: DU\n",
      "Epoch 3 (Step 003250): Train loss 4.150, Val loss 4.276\n",
      "Epoch 3 (Step 003500): Train loss 4.048, Val loss 4.265\n",
      "Epoch 3 (Step 003750): Train loss 3.961, Val loss 4.258\n",
      "Epoch 3 (Step 004000): Train loss 3.915, Val loss 4.207\n",
      "Epoch 3 (Step 004250): Train loss 3.818, Val loss 4.179\n",
      "Epoch 3 (Step 004500): Train loss 3.747, Val loss 4.166\n",
      "Every effort moves you, And, and I am a king, And, and I'll not so, and I'll be a little am a king, and I'll be a man, and I'll be a man I'll be a king, and I\n",
      "Epoch 4 (Step 004750): Train loss 3.756, Val loss 4.230\n",
      "Epoch 4 (Step 005000): Train loss 3.776, Val loss 4.250\n",
      "Epoch 4 (Step 005250): Train loss 3.746, Val loss 4.249\n",
      "Epoch 4 (Step 005500): Train loss 3.670, Val loss 4.229\n",
      "Epoch 4 (Step 005750): Train loss 3.621, Val loss 4.215\n",
      "Epoch 4 (Step 006000): Train loss 3.628, Val loss 4.203\n",
      "Every effort moves you, And, if you have done, And, by the queen, by the cause of your good my lord, I am not my lord, I am I am not so, I am not so, I am not so, I am\n",
      "Epoch 5 (Step 006250): Train loss 3.528, Val loss 4.276\n",
      "Epoch 5 (Step 006500): Train loss 3.664, Val loss 4.284\n",
      "Epoch 5 (Step 006750): Train loss 3.432, Val loss 4.276\n",
      "Epoch 5 (Step 007000): Train loss 3.381, Val loss 4.256\n",
      "Epoch 5 (Step 007250): Train loss 3.306, Val loss 4.238\n",
      "Epoch 5 (Step 007500): Train loss 3.253, Val loss 4.266\n",
      "Every effort moves you, And that the queen's life, and yet not the queen, that I will not the rest, my lord, my lord, my lord, my lord, my lord, my lord, my lord, my lord, my lord, my\n",
      "Epoch 6 (Step 007750): Train loss 3.185, Val loss 4.315\n",
      "Epoch 6 (Step 008000): Train loss 3.260, Val loss 4.341\n",
      "Epoch 6 (Step 008250): Train loss 3.180, Val loss 4.321\n",
      "Epoch 6 (Step 008500): Train loss 3.105, Val loss 4.287\n",
      "Epoch 6 (Step 008750): Train loss 3.120, Val loss 4.318\n",
      "Epoch 6 (Step 009000): Train loss 3.054, Val loss 4.318\n",
      "Every effort moves you, And I am a gentleman to the queen's death, Of the queen, I am I am the queen, and the queen's dead man, and the queen, and the queen, and the queen's the queen, and the queen\n",
      "Epoch 7 (Step 009250): Train loss 2.901, Val loss 4.446\n",
      "Epoch 7 (Step 009500): Train loss 2.921, Val loss 4.405\n",
      "Epoch 7 (Step 009750): Train loss 2.803, Val loss 4.430\n",
      "Epoch 7 (Step 010000): Train loss 2.781, Val loss 4.402\n",
      "Epoch 7 (Step 010250): Train loss 2.785, Val loss 4.370\n",
      "Epoch 7 (Step 010500): Train loss 2.665, Val loss 4.371\n",
      "Every effort moves you, When you have been used to beheld.  Lest you, my lord, my lord, my lord, my lord, my lord, my lord, my lord, my lord, my lord, my lord, my lord,\n",
      "Epoch 8 (Step 010750): Train loss 2.631, Val loss 4.500\n",
      "Epoch 8 (Step 011000): Train loss 2.573, Val loss 4.504\n",
      "Epoch 8 (Step 011250): Train loss 2.544, Val loss 4.515\n",
      "Epoch 8 (Step 011500): Train loss 2.413, Val loss 4.505\n",
      "Epoch 8 (Step 011750): Train loss 2.379, Val loss 4.502\n",
      "Epoch 8 (Step 012000): Train loss 2.330, Val loss 4.527\n",
      "Every effort moves you, And he shall be conducted.  LEONTES:  ANGELO, Paul, Paulina, Paulina, Paulina, Paulina, Paulina, my lord, I am one that'stles:  \n",
      "Epoch 9 (Step 012250): Train loss 2.276, Val loss 4.701\n",
      "Epoch 9 (Step 012500): Train loss 2.173, Val loss 4.684\n",
      "Epoch 9 (Step 012750): Train loss 2.058, Val loss 4.691\n",
      "Epoch 9 (Step 013000): Train loss 1.993, Val loss 4.678\n",
      "Epoch 9 (Step 013250): Train loss 1.999, Val loss 4.685\n",
      "Epoch 9 (Step 013500): Train loss 1.931, Val loss 4.653\n",
      "Every effort moves you Of our brother's grave. His actions are not furnish'd for ourself, The noble gentleman born to the people's welcome, that we have The noble gentleman of our brother's name, which you are beguiles, which you\n",
      "Epoch 10 (Step 013750): Train loss 1.838, Val loss 4.867\n",
      "Epoch 10 (Step 014000): Train loss 1.801, Val loss 4.938\n",
      "Epoch 10 (Step 014250): Train loss 1.724, Val loss 4.903\n",
      "Epoch 10 (Step 014500): Train loss 1.690, Val loss 4.882\n",
      "Epoch 10 (Step 014750): Train loss 1.668, Val loss 4.867\n",
      "Epoch 10 (Step 015000): Train loss 1.614, Val loss 4.854\n",
      "Every effort moves you, I'll show you in your embassage And make a good morrowsy weight of the king's name's name the king's name, which I have you forswear scour of the king'stchellenches\n",
      "Epoch 11 (Step 015250): Train loss 1.459, Val loss 5.087\n",
      "Epoch 11 (Step 015500): Train loss 1.425, Val loss 5.182\n",
      "Epoch 11 (Step 015750): Train loss 1.399, Val loss 5.097\n",
      "Epoch 11 (Step 016000): Train loss 1.423, Val loss 5.091\n",
      "Epoch 11 (Step 016250): Train loss 1.392, Val loss 5.074\n",
      "Epoch 11 (Step 016500): Train loss 1.260, Val loss 5.060\n",
      "Every effort moves you: I'll make a battery in the Tower: And, sir, sir, good lady, sir, good lady, and welcome, and welcome, good my lord, and welcome, good man, and welcome, and welcome, and welcome\n",
      "Epoch 12 (Step 016750): Train loss 1.239, Val loss 5.336\n",
      "Epoch 12 (Step 017000): Train loss 1.237, Val loss 5.327\n",
      "Epoch 12 (Step 017250): Train loss 1.202, Val loss 5.357\n",
      "Epoch 12 (Step 017500): Train loss 1.145, Val loss 5.387\n",
      "Epoch 12 (Step 017750): Train loss 1.034, Val loss 5.316\n",
      "Epoch 12 (Step 018000): Train loss 1.056, Val loss 5.392\n",
      "Every effort moves you see, For I have ever been to you.  Hath you that you know you have, my brother, my brother Montague, my brother, my brother, my brother, my brother, my brother, my brother, my brother\n",
      "Epoch 13 (Step 018250): Train loss 0.936, Val loss 5.573\n",
      "Epoch 13 (Step 018500): Train loss 0.980, Val loss 5.564\n",
      "Epoch 13 (Step 018750): Train loss 0.919, Val loss 5.592\n",
      "Epoch 13 (Step 019000): Train loss 0.951, Val loss 5.619\n",
      "Epoch 13 (Step 019250): Train loss 0.906, Val loss 5.606\n",
      "Epoch 13 (Step 019500): Train loss 0.842, Val loss 5.598\n",
      "Every effort moves you, And you shall have you be spared.  DUKE VINCENTIO: A boy, my daughter, my daughter, my brother, my daughter, my brother, my daughter, my brother Gloucester, AUMER\n",
      "Early stopping condition executed\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "num_epochs, eval_freq, eval_iter = 23, 250, 16\n",
    "start_context = 'Every effort moves you'\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "train_losses, val_losses, track_tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader,optimizer, device,\n",
    "    num_epochs, eval_freq, eval_iter, start_context, tokenizer, early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ed57c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:32:38.216870Z",
     "iopub.status.busy": "2025-11-17T22:32:38.216515Z",
     "iopub.status.idle": "2025-11-17T22:32:38.864757Z",
     "shell.execute_reply": "2025-11-17T22:32:38.864051Z"
    },
    "papermill": {
     "duration": 0.656586,
     "end_time": "2025-11-17T22:32:38.865931",
     "exception": false,
     "start_time": "2025-11-17T22:32:38.209345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      "Every effort moves you,\n",
      "Most noble prince, with that opinion shows majesty,\n",
      "I play the day some call'd the warlike Marcius withal sea, and\n"
     ]
    }
   ],
   "source": [
    "token_ids = model.generate(\n",
    "        idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "        max_new_tokens=30,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "        device=device,\n",
    "        temperature=1.4,\n",
    "        top_k=25,\n",
    "        eos_id='<|endoftext|>'\n",
    ")\n",
    "print('Output text:')\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990eb719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:32:38.879998Z",
     "iopub.status.busy": "2025-11-17T22:32:38.879589Z",
     "iopub.status.idle": "2025-11-17T22:32:40.872683Z",
     "shell.execute_reply": "2025-11-17T22:32:40.871928Z"
    },
    "papermill": {
     "duration": 2.001396,
     "end_time": "2025-11-17T22:32:40.873935",
     "exception": false,
     "start_time": "2025-11-17T22:32:38.872539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      "Every effort moves you.\n",
      "Come, ladies. far comes the caria forgiveness? The day was half his last!\n",
      "sound into it to him; say with him.\n",
      "Your prattsously: come about him to be out of his place; then the market-tender of him! And that givesves for tr frozen man oracle should you mock it presently.' Heland, you know it then be't look that does forget with fire.\n",
      "He speak again, to Berkeley, wept, we will keep him.\n",
      "beown find us. How. How many knave the next man use's again: he was anon comes unto himself to give you befall desired the people any sword to keep your bed be known! He chide us not. If God keep your resolution make you common deputy here was an executioner be good Comin's other.\n",
      "A shepherd make take us thus. But out our reward us take you are his sister'ser beards be much of\n"
     ]
    }
   ],
   "source": [
    "token_ids = model.generate(\n",
    "        idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "        max_new_tokens=200,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "        device=device,\n",
    "        temperature=2,\n",
    "        top_k=20,\n",
    "        eos_id='<|endoftext|>'\n",
    ")\n",
    "print('Output text:')\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01ad7a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:32:40.889145Z",
     "iopub.status.busy": "2025-11-17T22:32:40.888631Z",
     "iopub.status.idle": "2025-11-17T22:32:41.140635Z",
     "shell.execute_reply": "2025-11-17T22:32:41.139812Z"
    },
    "papermill": {
     "duration": 0.260775,
     "end_time": "2025-11-17T22:32:41.141785",
     "exception": false,
     "start_time": "2025-11-17T22:32:40.881010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      "How are you, are you that be 'ensed; thank me both\n",
      "than the court and be't is for my country: what I shall I must report forsworn;\n"
     ]
    }
   ],
   "source": [
    "token_ids = model.generate(\n",
    "        idx=text_to_token_ids(\"How are you, are you\", tokenizer),\n",
    "        max_new_tokens=30,\n",
    "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "        device=device,\n",
    "        temperature=2,\n",
    "        top_k=20,\n",
    "        eos_id='<|endoftext|>'\n",
    ")\n",
    "print('Output text:')\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcec23e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:32:41.156326Z",
     "iopub.status.busy": "2025-11-17T22:32:41.155700Z",
     "iopub.status.idle": "2025-11-17T22:33:06.609289Z",
     "shell.execute_reply": "2025-11-17T22:33:06.608722Z"
    },
    "papermill": {
     "duration": 25.462273,
     "end_time": "2025-11-17T22:33:06.610653",
     "exception": false,
     "start_time": "2025-11-17T22:32:41.148380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "846e30fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:33:06.624933Z",
     "iopub.status.busy": "2025-11-17T22:33:06.624738Z",
     "iopub.status.idle": "2025-11-17T22:33:07.734002Z",
     "shell.execute_reply": "2025-11-17T22:33:07.733374Z"
    },
    "papermill": {
     "duration": 1.117586,
     "end_time": "2025-11-17T22:33:07.735259",
     "exception": false,
     "start_time": "2025-11-17T22:33:06.617673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/kaggle/working/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b95908d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:33:07.749554Z",
     "iopub.status.busy": "2025-11-17T22:33:07.749357Z",
     "iopub.status.idle": "2025-11-17T22:33:08.978747Z",
     "shell.execute_reply": "2025-11-17T22:33:08.977944Z"
    },
    "papermill": {
     "duration": 1.238092,
     "end_time": "2025-11-17T22:33:08.980045",
     "exception": false,
     "start_time": "2025-11-17T22:33:07.741953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label='Training loss')\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label='Val loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel('Tokens seen')\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, track_tokens_seen, train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8762560,
     "sourceId": 13768280,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1410.633029,
   "end_time": "2025-11-17T22:33:11.540333",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-17T22:09:40.907304",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
